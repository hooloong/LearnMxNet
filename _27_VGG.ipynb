{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programdata\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "D:\\Programdata\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import gluonbook as gb\n",
    "from mxnet import nd, init, gluon\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "def vgg_block(num_convs, num_channels):\n",
    "    blk = nn.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        blk.add(nn.Conv2D(\n",
    "            num_channels, kernel_size=3, padding=1, activation='relu'))\n",
    "    blk.add(nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3\\times 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def vgg(conv_arch, num_outputs):\n",
    "    net = nn.Sequential()\n",
    "    # 卷积层部分\n",
    "    for (num_convs, num_channels) in conv_arch:\n",
    "        net.add(vgg_block(num_convs, num_channels))\n",
    "    # 全连接层部分\n",
    "    net.add(\n",
    "        nn.Dense(4096, activation=\"relu\"),\n",
    "        nn.Dropout(.5),\n",
    "        nn.Dense(4096, activation=\"relu\"),\n",
    "        nn.Dropout(.5),\n",
    "        nn.Dense(num_outputs))\n",
    "    return net\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential1 output shape:\t (1, 64, 112, 112)\n",
      "sequential2 output shape:\t (1, 128, 56, 56)\n",
      "sequential3 output shape:\t (1, 256, 28, 28)\n",
      "sequential4 output shape:\t (1, 512, 14, 14)\n",
      "sequential5 output shape:\t (1, 512, 7, 7)\n",
      "dense0 output shape:\t (1, 4096)\n",
      "dropout0 output shape:\t (1, 4096)\n",
      "dense1 output shape:\t (1, 4096)\n",
      "dropout1 output shape:\t (1, 4096)\n",
      "dense2 output shape:\t (1, 1000)\n"
     ]
    }
   ],
   "source": [
    "conv_arch = ((1,64), (1,128), (2,256), (2,512), (2,512))\n",
    "net = vgg(conv_arch, 1000)\n",
    "net.initialize()\n",
    "\n",
    "X = nd.random.uniform(shape=(1,1,224,224))\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.name, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio = 4\n",
    "small_conv_arch = [(pair[0], int(pair[1]/ratio)) for pair in conv_arch]\n",
    "net = vgg(small_conv_arch, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training on  gpu(0)\n",
      "Epoch 0. Loss: 0.909, Train acc 0.67, Test acc 0.86, Time 152.7 sec\n",
      "Epoch 1. Loss: 0.406, Train acc 0.85, Test acc 0.88, Time 131.5 sec\n",
      "Epoch 2. Loss: 0.332, Train acc 0.88, Test acc 0.90, Time 131.5 sec\n"
     ]
    }
   ],
   "source": [
    "ctx = gb.try_gpu()\n",
    "net.initialize(ctx=ctx, init=init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .05})\n",
    "\n",
    "train_data, test_data = gb.load_data_fashion_mnist(batch_size=128, resize=224)\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "gb.train(train_data, test_data, net, loss, trainer, ctx, num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG通过5个可以重复使用的卷积块来构造网络。根据卷积块里卷积层数目和输出通道不同可以定义出不同的VGG模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    VGG的计算比AlexNet慢很多，也需要很多的GPU内存。分析下原因。\n",
    "    尝试将FashionMNIST的高宽由224改成96，实验其带来的影响。\n",
    "    参考[1]里的表1来构造VGG其他常用模型，例如VGG16和VGG19。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
