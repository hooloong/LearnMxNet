{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programdata\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "D:\\Programdata\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import gluonbook as gb\n",
    "\n",
    "from mxnet import nd, init, gluon\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "class Inception(nn.Block):\n",
    "    # c1 - c4 为每条线路里的层的输出通道数。\n",
    "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # 线路 1，单 1 x 1 卷积层。\n",
    "        self.p1_1 = nn.Conv2D(c1, kernel_size=1, activation='relu')\n",
    "        # 线路 2，1 x 1 卷积层后接 3 x 3 卷积层。\n",
    "        self.p2_1 = nn.Conv2D(c2[0], kernel_size=1, activation='relu')\n",
    "        self.p2_2 = nn.Conv2D(c2[1], kernel_size=3, padding=1,\n",
    "                              activation='relu')\n",
    "        # 线路 3，1 x 1 卷积层后接 5 x 5 卷积层。\n",
    "        self.p3_1 = nn.Conv2D(c3[0], kernel_size=1, activation='relu')\n",
    "        self.p3_2 = nn.Conv2D(c3[1], kernel_size=5, padding=2,\n",
    "                              activation='relu')\n",
    "        # 线路 4，3 x 3最大池化层后接 1 x 1 卷积层。\n",
    "        self.p4_1 = nn.MaxPool2D(pool_size=3, strides=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2D(c4, kernel_size=1, activation='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = self.p1_1(x)\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # 在通道维上合并输出\n",
    "        return nd.concat(p1, p2, p3, p4, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b1 = nn.Sequential()\n",
    "b1.add(\n",
    "    nn.Conv2D(64, kernel_size=7, strides=2, padding=3, activation='relu'),\n",
    "    nn.MaxPool2D(pool_size=3, strides=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "b2 = nn.Sequential()\n",
    "b2.add(\n",
    "    nn.Conv2D(64, kernel_size=1),\n",
    "    nn.Conv2D(192, kernel_size=3, padding=1),\n",
    "    nn.MaxPool2D(pool_size=3, strides=2, padding=1)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "b3 = nn.Sequential()\n",
    "b3.add(\n",
    "    Inception(64, (96, 128), (16, 32), 32),\n",
    "    Inception(128, (128, 192), (32, 96), 64),\n",
    "    nn.MaxPool2D(pool_size=3, strides=2, padding=1)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b4 = nn.Sequential()\n",
    "b4.add(\n",
    "    Inception(192, (96, 208), (16, 48), 64),\n",
    "    Inception(160, (112, 224), (24, 64), 64),\n",
    "    Inception(128, (128, 256), (24, 64), 64),\n",
    "    Inception(112, (144, 288), (32, 64), 64),\n",
    "    Inception(256, (160, 320), (32, 128), 128),\n",
    "    nn.MaxPool2D(pool_size=3, strides=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b5 = nn.Sequential()\n",
    "b5.add(\n",
    "    Inception(256, (160, 320), (32, 128), 128),\n",
    "    Inception(384, (192, 384), (48, 128), 128),\n",
    "    nn.GlobalAvgPool2D()\n",
    ")\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(b1, b2, b3, b4, b5, nn.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential0 output shape:\t (1, 64, 24, 24)\n",
      "sequential1 output shape:\t (1, 192, 12, 12)\n",
      "sequential2 output shape:\t (1, 480, 6, 6)\n",
      "sequential3 output shape:\t (1, 832, 3, 3)\n",
      "sequential4 output shape:\t (1, 1024, 1, 1)\n",
      "dense0 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = nd.random.uniform(shape=(1,1,96,96))\n",
    "net.initialize()\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.name, 'output shape:\\t', X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training on  gpu(0)\n",
      "Epoch 0. Loss: 2.172, Train acc 0.20, Test acc 0.19, Time 101.2 sec\n",
      "Epoch 1. Loss: 0.782, Train acc 0.70, Test acc 0.81, Time 86.5 sec\n",
      "Epoch 2. Loss: 0.458, Train acc 0.83, Test acc 0.86, Time 86.5 sec\n",
      "Epoch 3. Loss: 0.375, Train acc 0.86, Test acc 0.88, Time 86.6 sec\n",
      "Epoch 4. Loss: 0.333, Train acc 0.87, Test acc 0.88, Time 86.7 sec\n",
      "Epoch 5. Loss: 0.306, Train acc 0.89, Test acc 0.89, Time 86.2 sec\n",
      "Epoch 6. Loss: 0.281, Train acc 0.89, Test acc 0.89, Time 86.4 sec\n",
      "Epoch 7. Loss: 0.264, Train acc 0.90, Test acc 0.89, Time 86.6 sec\n",
      "Epoch 8. Loss: 0.250, Train acc 0.90, Test acc 0.90, Time 86.6 sec\n",
      "Epoch 9. Loss: 0.237, Train acc 0.91, Test acc 0.91, Time 87.1 sec\n",
      "Epoch 10. Loss: 0.392, Train acc 0.86, Test acc 0.90, Time 86.7 sec\n",
      "Epoch 11. Loss: 0.236, Train acc 0.91, Test acc 0.88, Time 86.5 sec\n",
      "Epoch 12. Loss: 0.216, Train acc 0.92, Test acc 0.91, Time 86.9 sec\n",
      "Epoch 13. Loss: 0.200, Train acc 0.92, Test acc 0.91, Time 86.7 sec\n",
      "Epoch 14. Loss: 0.188, Train acc 0.93, Test acc 0.91, Time 86.8 sec\n"
     ]
    }
   ],
   "source": [
    "ctx = gb.try_gpu()\n",
    "net.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .1})\n",
    "train_data, test_data = gb.load_data_fashion_mnist(batch_size=128, resize=96)\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "gb.train(train_data, test_data, net, loss, trainer, ctx, num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    GoogLeNet有数个后续版本，尝试实现他们并运行看看有什么不一样。本小节介绍的是最先的版本 [1]。[2] 加入批量归一化层（后一小节将介绍），[3] 对Inception块做了调整。[4] 则加入了残差连接（后面小节将介绍）。\n",
    "    对比AlexNet、VGG和NiN、GoogLeNet的模型参数大小。分析为什么后两个网络可以显著减小模型大小。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Szegedy, Christian, et al. “Going deeper with convolutions.” CVPR, 2015.\n",
    "\n",
    "[2] Ioffe, Sergey, and Christian Szegedy. “Batch normalization: Accelerating deep network training by reducing internal covariate shift.” arXiv:1502.03167 (2015).\n",
    "\n",
    "[3] Szegedy, Christian, et al. “Rethinking the inception architecture for computer vision.” CVPR. 2016.\n",
    "\n",
    "[4] Szegedy, Christian, et al. “Inception-v4, inception-resnet and the impact of residual connections on learning.” AAAI. 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
